{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "33ffb1a763d44a219b20d8ef951a598c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_5b7bb05e023c4e1bb09cb74042a4e258",
              "IPY_MODEL_3d980c4c51a14e29bea95a3631d1c68c",
              "IPY_MODEL_c08b1c0860774438a850565746b83e48"
            ],
            "layout": "IPY_MODEL_4640bec2dd84484ca90fbd5b6f80d3d1"
          }
        },
        "5b7bb05e023c4e1bb09cb74042a4e258": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_71e4b05b7aaf4b6ebe3ebb66507c1213",
            "placeholder": "​",
            "style": "IPY_MODEL_ecb16d7cb4714d92b09c2a6784e492b2",
            "value": "100%"
          }
        },
        "3d980c4c51a14e29bea95a3631d1c68c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ec5b4ba565fa40fbb5234f05aca69906",
            "max": 6983030,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_a2e5bac48de544b2b9eb243924d99a46",
            "value": 6983030
          }
        },
        "c08b1c0860774438a850565746b83e48": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d936191b64d34e32a8b9becbcb898706",
            "placeholder": "​",
            "style": "IPY_MODEL_38df309fd46e4f379a54c6db87f40cd7",
            "value": " 6.66M/6.66M [00:00&lt;00:00, 4.17MB/s]"
          }
        },
        "4640bec2dd84484ca90fbd5b6f80d3d1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "71e4b05b7aaf4b6ebe3ebb66507c1213": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ecb16d7cb4714d92b09c2a6784e492b2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "ec5b4ba565fa40fbb5234f05aca69906": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a2e5bac48de544b2b9eb243924d99a46": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "d936191b64d34e32a8b9becbcb898706": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "38df309fd46e4f379a54c6db87f40cd7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "%cd \"/content/drive/MyDrive\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vLs5adrJia3m",
        "outputId": "292710a7-2187-407b-c26f-106fbb0fb81a"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "/content/drive/MyDrive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/ultralytics/yolov5  # clone"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gH5NMHM1egio",
        "outputId": "af6e6293-63a0-4450-d6f1-2cc9b8e193f1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fatal: destination path 'yolov5' already exists and is not an empty directory.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%cd \"/content/drive/MyDrive\"\n",
        "\n",
        "# Download COCO128\n",
        "torch.hub.download_url_to_file('https://github.com/ultralytics/yolov5/releases/download/v1.0/coco128.zip', 'tmp.zip')\n",
        "!unzip -q tmp.zip -d ./ && rm tmp.zip\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 66,
          "referenced_widgets": [
            "33ffb1a763d44a219b20d8ef951a598c",
            "5b7bb05e023c4e1bb09cb74042a4e258",
            "3d980c4c51a14e29bea95a3631d1c68c",
            "c08b1c0860774438a850565746b83e48",
            "4640bec2dd84484ca90fbd5b6f80d3d1",
            "71e4b05b7aaf4b6ebe3ebb66507c1213",
            "ecb16d7cb4714d92b09c2a6784e492b2",
            "ec5b4ba565fa40fbb5234f05aca69906",
            "a2e5bac48de544b2b9eb243924d99a46",
            "d936191b64d34e32a8b9becbcb898706",
            "38df309fd46e4f379a54c6db87f40cd7"
          ]
        },
        "id": "uIwqWmaZqwfW",
        "outputId": "a32a0fc3-b518-4981-caee-a47093ec39cd"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/MyDrive\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  0%|          | 0.00/6.66M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "33ffb1a763d44a219b20d8ef951a598c"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%cd yolov5\n",
        "%pip install -qr requirements.txt  # install\n",
        "\n",
        "import torch\n",
        "import utils\n",
        "display = utils.notebook_init()  # checks"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TD5IaefviXfR",
        "outputId": "b0a592cf-ec98-4706-dc45-b056d2a5f97a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "YOLOv5 🚀 v6.2-137-gfda8aa5 Python-3.7.14 torch-1.12.1+cu113 CPU\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Setup complete ✅ (2 CPUs, 12.7 GB RAM, 37.0/107.7 GB disk)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "\n",
        "#파이토치 버전 확인, cuda device properties 확인\n",
        "print('torch %s %s' % (torch.__version__, torch.cuda.get_device_properties(0) if torch.cuda.is_available() else 'CPU'))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5gcBnsRx2Dav",
        "outputId": "ae6f4de1-15d9-44bf-d229-95c80d189f19"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch 1.12.1+cu113 CPU\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import shutil\n",
        "sourcepath = './data/images/'\n",
        "sourcefiles = os.listdir(sourcepath)\n",
        "destinationpath = './data/labels/'\n",
        "for file in sourcefiles:\n",
        "  if file.endswith('.txt'):\n",
        "    shutil.move(os.path.join(sourcepath, file), os.path.join(destinationpath, file))"
      ],
      "metadata": {
        "id": "MExPkzKyYKxb"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Validate YOLOv5s on COCO val\n",
        "#!python val.py --weights yolov5s.pt --data coco128.yaml --img 224 --half"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VsgPiY4wc9ne",
        "outputId": "bdcc4f1f-8f97-46fa-b342-39b5bd2ae6ca"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[34m\u001b[1mval: \u001b[0mdata=/content/drive/MyDrive/yolov5/data/coco128.yaml, weights=['yolov5s.pt'], batch_size=32, imgsz=224, conf_thres=0.001, iou_thres=0.6, max_det=300, task=val, device=, workers=8, single_cls=False, augment=False, verbose=False, save_txt=False, save_hybrid=False, save_conf=False, save_json=False, project=runs/val, name=exp, exist_ok=False, half=True, dnn=False\n",
            "YOLOv5 🚀 v6.2-137-gfda8aa5 Python-3.7.14 torch-1.12.1+cu113 CPU\n",
            "\n",
            "Fusing layers... \n",
            "YOLOv5s summary: 213 layers, 7225885 parameters, 0 gradients\n",
            "Traceback (most recent call last):\n",
            "  File \"val.py\", line 407, in <module>\n",
            "    main(opt)\n",
            "  File \"val.py\", line 380, in main\n",
            "    run(**vars(opt))\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/torch/autograd/grad_mode.py\", line 27, in decorate_context\n",
            "    return func(*args, **kwargs)\n",
            "  File \"val.py\", line 169, in run\n",
            "    assert ncm == nc, f'{weights} ({ncm} classes) trained on different --data than what you passed ({nc} ' \\\n",
            "AssertionError: ['yolov5s.pt'] (80 classes) trained on different --data than what you passed (3 classes). Pass correct combination of --weights and --data that are trained together.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import shutil\n",
        "sourcepath = './data/labels/'\n",
        "sourcefiles = os.listdir(sourcepath)\n",
        "for file in sourcefiles:\n",
        "  f = open(os.path.join(sourcepath, file))\n",
        "  line = f.readline()\n",
        "  while(line):\n",
        "    if int(line.split()[0]) > 2:\n",
        "      print(file)\n",
        "    line = f.readline()"
      ],
      "metadata": {
        "id": "5yw3Sn1Wpawe"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sourcepath = './yolov5/data/images/'\n",
        "sourcefiles = os.listdir(sourcepath)\n",
        "destinationpath = './coco128/images/train2017'\n",
        "for file in sourcefiles:\n",
        "  shutil.move(os.path.join(sourcepath, file), os.path.join(destinationpath, file))"
      ],
      "metadata": {
        "id": "tDGCR5p0yL5C"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sourcepath = './yolov5/data/labels/'\n",
        "sourcefiles = os.listdir(sourcepath)\n",
        "destinationpath = './coco128/labels/train2017'\n",
        "for file in sourcefiles:\n",
        "  shutil.move(os.path.join(sourcepath, file), os.path.join(destinationpath, file))"
      ],
      "metadata": {
        "id": "whhaECMuuWCj"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Train YOLOv5s on COCO128 for 3 epochs\n",
        "%cd yolov5/\n",
        "!python train.py --img 224 --batch 32 --epochs 5 --data coco128.yaml --weights yolov5s.pt --cache"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CGMG8fuYiDAd",
        "outputId": "7b6446f7-2995-4502-a23a-7cd8a4fbbdc6"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Errno 2] No such file or directory: 'yolov5/'\n",
            "/content/drive/MyDrive/yolov5\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: (1) Create a W&B account\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: (2) Use an existing W&B account\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: (3) Don't visualize my results\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Enter your choice: (30 second timeout) \n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: W&B disabled due to login timeout.\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mweights=yolov5s.pt, cfg=, data=coco128.yaml, hyp=data/hyps/hyp.scratch-low.yaml, epochs=5, batch_size=32, imgsz=224, rect=False, resume=False, nosave=False, noval=False, noautoanchor=False, noplots=False, evolve=None, bucket=, cache=ram, image_weights=False, device=, multi_scale=False, single_cls=False, optimizer=SGD, sync_bn=False, workers=8, project=runs/train, name=exp, exist_ok=False, quad=False, cos_lr=False, label_smoothing=0.0, patience=100, freeze=[0], save_period=-1, seed=0, local_rank=-1, entity=None, upload_dataset=False, bbox_interval=-1, artifact_alias=latest\n",
            "\u001b[34m\u001b[1mgithub: \u001b[0m⚠️ YOLOv5 is out of date by 4 commits. Use `git pull` or `git clone https://github.com/ultralytics/yolov5` to update.\n",
            "YOLOv5 🚀 v6.2-137-gfda8aa5 Python-3.7.14 torch-1.12.1+cu113 CPU\n",
            "\n",
            "\u001b[34m\u001b[1mhyperparameters: \u001b[0mlr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=0.05, cls=0.5, cls_pw=1.0, obj=1.0, obj_pw=1.0, iou_t=0.2, anchor_t=4.0, fl_gamma=0.0, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0\n",
            "\u001b[34m\u001b[1mWeights & Biases: \u001b[0mrun 'pip install wandb' to automatically track and visualize YOLOv5 🚀 runs in Weights & Biases\n",
            "\u001b[34m\u001b[1mClearML: \u001b[0mrun 'pip install clearml' to automatically track, visualize and remotely train YOLOv5 🚀 in ClearML\n",
            "\u001b[34m\u001b[1mComet: \u001b[0mrun 'pip install comet_ml' to automatically track and visualize YOLOv5 🚀 runs in Comet\n",
            "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs/train', view at http://localhost:6006/\n",
            "Downloading https://github.com/ultralytics/yolov5/releases/download/v6.2/yolov5s.pt to yolov5s.pt...\n",
            "100% 14.1M/14.1M [00:00<00:00, 44.7MB/s]\n",
            "\n",
            "Overriding model.yaml nc=80 with nc=3\n",
            "\n",
            "                 from  n    params  module                                  arguments                     \n",
            "  0                -1  1      3520  models.common.Conv                      [3, 32, 6, 2, 2]              \n",
            "  1                -1  1     18560  models.common.Conv                      [32, 64, 3, 2]                \n",
            "  2                -1  1     18816  models.common.C3                        [64, 64, 1]                   \n",
            "  3                -1  1     73984  models.common.Conv                      [64, 128, 3, 2]               \n",
            "  4                -1  2    115712  models.common.C3                        [128, 128, 2]                 \n",
            "  5                -1  1    295424  models.common.Conv                      [128, 256, 3, 2]              \n",
            "  6                -1  3    625152  models.common.C3                        [256, 256, 3]                 \n",
            "  7                -1  1   1180672  models.common.Conv                      [256, 512, 3, 2]              \n",
            "  8                -1  1   1182720  models.common.C3                        [512, 512, 1]                 \n",
            "  9                -1  1    656896  models.common.SPPF                      [512, 512, 5]                 \n",
            " 10                -1  1    131584  models.common.Conv                      [512, 256, 1, 1]              \n",
            " 11                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \n",
            " 12           [-1, 6]  1         0  models.common.Concat                    [1]                           \n",
            " 13                -1  1    361984  models.common.C3                        [512, 256, 1, False]          \n",
            " 14                -1  1     33024  models.common.Conv                      [256, 128, 1, 1]              \n",
            " 15                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \n",
            " 16           [-1, 4]  1         0  models.common.Concat                    [1]                           \n",
            " 17                -1  1     90880  models.common.C3                        [256, 128, 1, False]          \n",
            " 18                -1  1    147712  models.common.Conv                      [128, 128, 3, 2]              \n",
            " 19          [-1, 14]  1         0  models.common.Concat                    [1]                           \n",
            " 20                -1  1    296448  models.common.C3                        [256, 256, 1, False]          \n",
            " 21                -1  1    590336  models.common.Conv                      [256, 256, 3, 2]              \n",
            " 22          [-1, 10]  1         0  models.common.Concat                    [1]                           \n",
            " 23                -1  1   1182720  models.common.C3                        [512, 512, 1, False]          \n",
            " 24      [17, 20, 23]  1     21576  models.yolo.Detect                      [3, [[10, 13, 16, 30, 33, 23], [30, 61, 62, 45, 59, 119], [116, 90, 156, 198, 373, 326]], [128, 256, 512]]\n",
            "Model summary: 214 layers, 7027720 parameters, 7027720 gradients, 16.0 GFLOPs\n",
            "\n",
            "Transferred 343/349 items from yolov5s.pt\n",
            "\u001b[34m\u001b[1moptimizer:\u001b[0m SGD(lr=0.01) with parameter groups 57 weight(decay=0.0), 60 weight(decay=0.0005), 60 bias\n",
            "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01), CLAHE(p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mScanning '/content/drive/MyDrive/coco128/labels/train2017.cache' images and labels... 449 found, 0 missing, 6 empty, 0 corrupt: 100% 449/449 [00:00<?, ?it/s]\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mCaching images (0.1GB ram): 100% 449/449 [00:04<00:00, 107.80it/s]\n",
            "\u001b[34m\u001b[1mval: \u001b[0mScanning '/content/drive/MyDrive/coco128/labels/train2017.cache' images and labels... 449 found, 0 missing, 6 empty, 0 corrupt: 100% 449/449 [00:00<?, ?it/s]\n",
            "\u001b[34m\u001b[1mval: \u001b[0mCaching images (0.1GB ram): 100% 449/449 [00:05<00:00, 75.86it/s]\n",
            "\n",
            "\u001b[34m\u001b[1mAutoAnchor: \u001b[0m3.64 anchors/target, 0.995 Best Possible Recall (BPR). Current anchors are a good fit to dataset ✅\n",
            "Plotting labels to runs/train/exp/labels.jpg... \n",
            "Image sizes 224 train, 224 val\n",
            "Using 2 dataloader workers\n",
            "Logging results to \u001b[1mruns/train/exp\u001b[0m\n",
            "Starting training for 5 epochs...\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "        0/4         0G     0.1264   0.009604      1.016          5        224: 100% 15/15 [01:20<00:00,  5.34s/it]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 8/8 [00:24<00:00,  3.08s/it]\n",
            "                   all        449       1045    0.00067     0.0956   0.000607   0.000171\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "        1/4         0G     0.1252    0.01046     0.6378          5        224: 100% 15/15 [01:19<00:00,  5.32s/it]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 8/8 [00:26<00:00,  3.26s/it]\n",
            "                   all        449       1045    0.00952     0.0117    0.00307   0.000714\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "        2/4         0G     0.1158    0.01071     0.2462          3        224: 100% 15/15 [01:28<00:00,  5.89s/it]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 8/8 [00:26<00:00,  3.34s/it]\n",
            "                   all        449       1045     0.0228     0.0659    0.00738    0.00174\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "        3/4         0G     0.1099    0.01421     0.1309          8        224: 100% 15/15 [01:16<00:00,  5.12s/it]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 8/8 [00:27<00:00,  3.50s/it]\n",
            "                   all        449       1045     0.0433      0.109     0.0216    0.00473\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "        4/4         0G      0.102    0.01393     0.1174          5        224: 100% 15/15 [01:16<00:00,  5.12s/it]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 8/8 [00:27<00:00,  3.42s/it]\n",
            "                   all        449       1045     0.0683      0.164     0.0332    0.00716\n",
            "\n",
            "5 epochs completed in 0.150 hours.\n",
            "Optimizer stripped from runs/train/exp/weights/last.pt, 14.3MB\n",
            "Optimizer stripped from runs/train/exp/weights/best.pt, 14.3MB\n",
            "\n",
            "Validating runs/train/exp/weights/best.pt...\n",
            "Fusing layers... \n",
            "Model summary: 157 layers, 7018216 parameters, 0 gradients, 15.8 GFLOPs\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 8/8 [00:25<00:00,  3.13s/it]\n",
            "                   all        449       1045     0.0677      0.163      0.033    0.00714\n",
            "                  ball        449        343     0.0817      0.143     0.0256     0.0065\n",
            "                  goal        449        404          0          0    0.00086   0.000219\n",
            "                keeper        449        298      0.121      0.346     0.0726     0.0147\n",
            "Results saved to \u001b[1mruns/train/exp\u001b[0m\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python export.py --weights yolov5s.pt --include torchscript onnx"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ejcweHA94cRl",
        "outputId": "02786c45-a645-4a69-96ba-9c5e37cec59a"
      },
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[34m\u001b[1mexport: \u001b[0mdata=data/coco128.yaml, weights=['yolov5s.pt'], imgsz=[640, 640], batch_size=1, device=cpu, half=False, inplace=False, keras=False, optimize=False, int8=False, dynamic=False, simplify=False, opset=12, verbose=False, workspace=4, nms=False, agnostic_nms=False, topk_per_class=100, topk_all=100, iou_thres=0.45, conf_thres=0.25, include=['torchscript', 'onnx']\n",
            "YOLOv5 🚀 v6.2-137-gfda8aa5 Python-3.7.14 torch-1.12.1+cu113 CPU\n",
            "\n",
            "Fusing layers... \n",
            "YOLOv5s summary: 213 layers, 7225885 parameters, 0 gradients\n",
            "\n",
            "\u001b[34m\u001b[1mPyTorch:\u001b[0m starting from yolov5s.pt with output shape (1, 25200, 85) (14.1 MB)\n",
            "\n",
            "\u001b[34m\u001b[1mTorchScript:\u001b[0m starting export with torch 1.12.1+cu113...\n",
            "\u001b[34m\u001b[1mTorchScript:\u001b[0m export success ✅ 3.5s, saved as yolov5s.torchscript (28.0 MB)\n",
            "\u001b[31m\u001b[1mrequirements:\u001b[0m YOLOv5 requirement \"onnx\" not found, attempting AutoUpdate...\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting onnx\n",
            "  Downloading onnx-1.12.0-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (13.1 MB)\n",
            "Requirement already satisfied: numpy>=1.16.6 in /usr/local/lib/python3.7/dist-packages (from onnx) (1.21.6)\n",
            "Requirement already satisfied: protobuf<=3.20.1,>=3.12.2 in /usr/local/lib/python3.7/dist-packages (from onnx) (3.17.3)\n",
            "Requirement already satisfied: typing-extensions>=3.6.2.1 in /usr/local/lib/python3.7/dist-packages (from onnx) (4.1.1)\n",
            "Requirement already satisfied: six>=1.9 in /usr/local/lib/python3.7/dist-packages (from protobuf<=3.20.1,>=3.12.2->onnx) (1.15.0)\n",
            "Installing collected packages: onnx\n",
            "Successfully installed onnx-1.12.0\n",
            "\n",
            "\u001b[31m\u001b[1mrequirements:\u001b[0m 1 package updated per ['onnx']\n",
            "\u001b[31m\u001b[1mrequirements:\u001b[0m ⚠️ \u001b[1mRestart runtime or rerun command for updates to take effect\u001b[0m\n",
            "\n",
            "\n",
            "\u001b[34m\u001b[1mONNX:\u001b[0m starting export with onnx 1.12.0...\n",
            "\u001b[34m\u001b[1mONNX:\u001b[0m export success ✅ 11.4s, saved as yolov5s.onnx (28.0 MB)\n",
            "\n",
            "Export complete (16.2s)\n",
            "Results saved to \u001b[1m/content/drive/MyDrive/yolov5\u001b[0m\n",
            "Detect:          python detect.py --weights yolov5s.onnx \n",
            "Validate:        python val.py --weights yolov5s.onnx \n",
            "PyTorch Hub:     model = torch.hub.load('ultralytics/yolov5', 'custom', 'yolov5s.onnx')\n",
            "Visualize:       https://netron.app\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "print(tf.__version__)\n",
        "!PYTHONPATH=. python3 ./models/tf.py --weight ./runs/train/exp/weights/best.pt --img 224 "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kGzBg31_6a_G",
        "outputId": "59f04646-e7d8-4baf-8bf6-accfaae6205a"
      },
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2.8.2\n",
            "\u001b[34m\u001b[1mmodels/tf: \u001b[0mweights=./runs/train/exp/weights/best.pt, imgsz=[224, 224], batch_size=1, dynamic=False\n",
            "Model summary: 214 layers, 7027720 parameters, 0 gradients, 16.0 GFLOPs\n",
            "2022-09-19 18:06:38.771624: E tensorflow/stream_executor/cuda/cuda_driver.cc:271] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected\n",
            "\n",
            "                 from  n    params  module                                  arguments                     \n",
            "  0                -1  1      3520  models.common.Conv                      [3, 32, 6, 2, 2]              \n",
            "  1                -1  1     18560  models.common.Conv                      [32, 64, 3, 2]                \n",
            "  2                -1  1     18816  models.common.C3                        [64, 64, 1]                   \n",
            "  3                -1  1     73984  models.common.Conv                      [64, 128, 3, 2]               \n",
            "  4                -1  1    115712  models.common.C3                        [128, 128, 2]                 \n",
            "  5                -1  1    295424  models.common.Conv                      [128, 256, 3, 2]              \n",
            "  6                -1  1    625152  models.common.C3                        [256, 256, 3]                 \n",
            "  7                -1  1   1180672  models.common.Conv                      [256, 512, 3, 2]              \n",
            "  8                -1  1   1182720  models.common.C3                        [512, 512, 1]                 \n",
            "  9                -1  1    656896  models.common.SPPF                      [512, 512, 5]                 \n",
            " 10                -1  1    131584  models.common.Conv                      [512, 256, 1, 1]              \n",
            " 11                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \n",
            " 12           [-1, 6]  1         0  models.common.Concat                    [1]                           \n",
            " 13                -1  1    361984  models.common.C3                        [512, 256, 1, False]          \n",
            " 14                -1  1     33024  models.common.Conv                      [256, 128, 1, 1]              \n",
            " 15                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \n",
            " 16           [-1, 4]  1         0  models.common.Concat                    [1]                           \n",
            " 17                -1  1     90880  models.common.C3                        [256, 128, 1, False]          \n",
            " 18                -1  1    147712  models.common.Conv                      [128, 128, 3, 2]              \n",
            " 19          [-1, 14]  1         0  models.common.Concat                    [1]                           \n",
            " 20                -1  1    296448  models.common.C3                        [256, 256, 1, False]          \n",
            " 21                -1  1    590336  models.common.Conv                      [256, 256, 3, 2]              \n",
            " 22          [-1, 10]  1         0  models.common.Concat                    [1]                           \n",
            " 23                -1  1   1182720  models.common.C3                        [512, 512, 1, False]          \n",
            " 24      [17, 20, 23]  1     21576  models.yolo.Detect                      [3, [[10, 13, 16, 30, 33, 23], [30, 61, 62, 45, 59, 119], [116, 90, 156, 198, 373, 326]], [128, 256, 512], [224, 224]]\n",
            "Model: \"model\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                   Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            " input_1 (InputLayer)           [(1, 224, 224, 3)]   0           []                               \n",
            "                                                                                                  \n",
            " tf_conv (TFConv)               (1, 112, 112, 32)    3584        ['input_1[0][0]']                \n",
            "                                                                                                  \n",
            " tf_conv_1 (TFConv)             (1, 56, 56, 64)      18688       ['tf_conv[0][0]']                \n",
            "                                                                                                  \n",
            " tfc3 (TFC3)                    (1, 56, 56, 64)      19200       ['tf_conv_1[0][0]']              \n",
            "                                                                                                  \n",
            " tf_conv_7 (TFConv)             (1, 28, 28, 128)     74240       ['tfc3[0][0]']                   \n",
            "                                                                                                  \n",
            " tfc3_1 (TFC3)                  (1, 28, 28, 128)     116736      ['tf_conv_7[0][0]']              \n",
            "                                                                                                  \n",
            " tf_conv_15 (TFConv)            (1, 14, 14, 256)     295936      ['tfc3_1[0][0]']                 \n",
            "                                                                                                  \n",
            " tfc3_2 (TFC3)                  (1, 14, 14, 256)     627712      ['tf_conv_15[0][0]']             \n",
            "                                                                                                  \n",
            " tf_conv_25 (TFConv)            (1, 7, 7, 512)       1181696     ['tfc3_2[0][0]']                 \n",
            "                                                                                                  \n",
            " tfc3_3 (TFC3)                  (1, 7, 7, 512)       1185792     ['tf_conv_25[0][0]']             \n",
            "                                                                                                  \n",
            " tfsppf (TFSPPF)                (1, 7, 7, 512)       658432      ['tfc3_3[0][0]']                 \n",
            "                                                                                                  \n",
            " tf_conv_33 (TFConv)            (1, 7, 7, 256)       132096      ['tfsppf[0][0]']                 \n",
            "                                                                                                  \n",
            " tf_upsample (TFUpsample)       (1, 14, 14, 256)     0           ['tf_conv_33[0][0]']             \n",
            "                                                                                                  \n",
            " tf_concat (TFConcat)           (1, 14, 14, 512)     0           ['tf_upsample[0][0]',            \n",
            "                                                                  'tfc3_2[0][0]']                 \n",
            "                                                                                                  \n",
            " tfc3_4 (TFC3)                  (1, 14, 14, 256)     363520      ['tf_concat[0][0]']              \n",
            "                                                                                                  \n",
            " tf_conv_39 (TFConv)            (1, 14, 14, 128)     33280       ['tfc3_4[0][0]']                 \n",
            "                                                                                                  \n",
            " tf_upsample_1 (TFUpsample)     (1, 28, 28, 128)     0           ['tf_conv_39[0][0]']             \n",
            "                                                                                                  \n",
            " tf_concat_1 (TFConcat)         (1, 28, 28, 256)     0           ['tf_upsample_1[0][0]',          \n",
            "                                                                  'tfc3_1[0][0]']                 \n",
            "                                                                                                  \n",
            " tfc3_5 (TFC3)                  (1, 28, 28, 128)     91648       ['tf_concat_1[0][0]']            \n",
            "                                                                                                  \n",
            " tf_conv_45 (TFConv)            (1, 14, 14, 128)     147968      ['tfc3_5[0][0]']                 \n",
            "                                                                                                  \n",
            " tf_concat_2 (TFConcat)         (1, 14, 14, 256)     0           ['tf_conv_45[0][0]',             \n",
            "                                                                  'tf_conv_39[0][0]']             \n",
            "                                                                                                  \n",
            " tfc3_6 (TFC3)                  (1, 14, 14, 256)     297984      ['tf_concat_2[0][0]']            \n",
            "                                                                                                  \n",
            " tf_conv_51 (TFConv)            (1, 7, 7, 256)       590848      ['tfc3_6[0][0]']                 \n",
            "                                                                                                  \n",
            " tf_concat_3 (TFConcat)         (1, 7, 7, 512)       0           ['tf_conv_51[0][0]',             \n",
            "                                                                  'tf_conv_33[0][0]']             \n",
            "                                                                                                  \n",
            " tfc3_7 (TFC3)                  (1, 7, 7, 512)       1185792     ['tf_concat_3[0][0]']            \n",
            "                                                                                                  \n",
            " tf_detect (TFDetect)           ((1, 3087, 8),       21576       ['tfc3_5[0][0]',                 \n",
            "                                 [(1, 784, 3, 8),                 'tfc3_6[0][0]',                 \n",
            "                                 (1, 196, 3, 8),                  'tfc3_7[0][0]']                 \n",
            "                                 (1, 49, 3, 8)])                                                  \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 7,046,728\n",
            "Trainable params: 7,027,720\n",
            "Non-trainable params: 19,008\n",
            "__________________________________________________________________________________________________\n",
            "PyTorch, TensorFlow and Keras models successfully verified.\n",
            "Use export.py for TF model export.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python export.py --weights yolov5s.pt --include tflite"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jd0eetis7y6t",
        "outputId": "d6cfbf36-6f2e-4766-8ca1-8eaa598abc9c"
      },
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[34m\u001b[1mexport: \u001b[0mdata=data/coco128.yaml, weights=['yolov5s.pt'], imgsz=[640, 640], batch_size=1, device=cpu, half=False, inplace=False, keras=False, optimize=False, int8=False, dynamic=False, simplify=False, opset=12, verbose=False, workspace=4, nms=False, agnostic_nms=False, topk_per_class=100, topk_all=100, iou_thres=0.45, conf_thres=0.25, include=['tflite']\n",
            "YOLOv5 🚀 v6.2-137-gfda8aa5 Python-3.7.14 torch-1.12.1+cu113 CPU\n",
            "\n",
            "Fusing layers... \n",
            "YOLOv5s summary: 213 layers, 7225885 parameters, 0 gradients\n",
            "\n",
            "\u001b[34m\u001b[1mPyTorch:\u001b[0m starting from yolov5s.pt with output shape (1, 25200, 85) (14.1 MB)\n",
            "\n",
            "\u001b[34m\u001b[1mTensorFlow SavedModel:\u001b[0m starting export with tensorflow 2.8.2...\n",
            "\n",
            "                 from  n    params  module                                  arguments                     \n",
            "2022-09-19 18:08:15.263915: E tensorflow/stream_executor/cuda/cuda_driver.cc:271] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected\n",
            "  0                -1  1      3520  models.common.Conv                      [3, 32, 6, 2, 2]              \n",
            "  1                -1  1     18560  models.common.Conv                      [32, 64, 3, 2]                \n",
            "  2                -1  1     18816  models.common.C3                        [64, 64, 1]                   \n",
            "  3                -1  1     73984  models.common.Conv                      [64, 128, 3, 2]               \n",
            "  4                -1  1    115712  models.common.C3                        [128, 128, 2]                 \n",
            "  5                -1  1    295424  models.common.Conv                      [128, 256, 3, 2]              \n",
            "  6                -1  1    625152  models.common.C3                        [256, 256, 3]                 \n",
            "  7                -1  1   1180672  models.common.Conv                      [256, 512, 3, 2]              \n",
            "  8                -1  1   1182720  models.common.C3                        [512, 512, 1]                 \n",
            "  9                -1  1    656896  models.common.SPPF                      [512, 512, 5]                 \n",
            " 10                -1  1    131584  models.common.Conv                      [512, 256, 1, 1]              \n",
            " 11                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \n",
            " 12           [-1, 6]  1         0  models.common.Concat                    [1]                           \n",
            " 13                -1  1    361984  models.common.C3                        [512, 256, 1, False]          \n",
            " 14                -1  1     33024  models.common.Conv                      [256, 128, 1, 1]              \n",
            " 15                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \n",
            " 16           [-1, 4]  1         0  models.common.Concat                    [1]                           \n",
            " 17                -1  1     90880  models.common.C3                        [256, 128, 1, False]          \n",
            " 18                -1  1    147712  models.common.Conv                      [128, 128, 3, 2]              \n",
            " 19          [-1, 14]  1         0  models.common.Concat                    [1]                           \n",
            " 20                -1  1    296448  models.common.C3                        [256, 256, 1, False]          \n",
            " 21                -1  1    590336  models.common.Conv                      [256, 256, 3, 2]              \n",
            " 22          [-1, 10]  1         0  models.common.Concat                    [1]                           \n",
            " 23                -1  1   1182720  models.common.C3                        [512, 512, 1, False]          \n",
            " 24      [17, 20, 23]  1    229245  models.yolo.Detect                      [80, [[10, 13, 16, 30, 33, 23], [30, 61, 62, 45, 59, 119], [116, 90, 156, 198, 373, 326]], [128, 256, 512], [640, 640]]\n",
            "Model: \"model\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                   Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            " input_1 (InputLayer)           [(1, 640, 640, 3)]   0           []                               \n",
            "                                                                                                  \n",
            " tf_conv (TFConv)               (1, 320, 320, 32)    3488        ['input_1[0][0]']                \n",
            "                                                                                                  \n",
            " tf_conv_1 (TFConv)             (1, 160, 160, 64)    18496       ['tf_conv[0][0]']                \n",
            "                                                                                                  \n",
            " tfc3 (TFC3)                    (1, 160, 160, 64)    18624       ['tf_conv_1[0][0]']              \n",
            "                                                                                                  \n",
            " tf_conv_7 (TFConv)             (1, 80, 80, 128)     73856       ['tfc3[0][0]']                   \n",
            "                                                                                                  \n",
            " tfc3_1 (TFC3)                  (1, 80, 80, 128)     115200      ['tf_conv_7[0][0]']              \n",
            "                                                                                                  \n",
            " tf_conv_15 (TFConv)            (1, 40, 40, 256)     295168      ['tfc3_1[0][0]']                 \n",
            "                                                                                                  \n",
            " tfc3_2 (TFC3)                  (1, 40, 40, 256)     623872      ['tf_conv_15[0][0]']             \n",
            "                                                                                                  \n",
            " tf_conv_25 (TFConv)            (1, 20, 20, 512)     1180160     ['tfc3_2[0][0]']                 \n",
            "                                                                                                  \n",
            " tfc3_3 (TFC3)                  (1, 20, 20, 512)     1181184     ['tf_conv_25[0][0]']             \n",
            "                                                                                                  \n",
            " tfsppf (TFSPPF)                (1, 20, 20, 512)     656128      ['tfc3_3[0][0]']                 \n",
            "                                                                                                  \n",
            " tf_conv_33 (TFConv)            (1, 20, 20, 256)     131328      ['tfsppf[0][0]']                 \n",
            "                                                                                                  \n",
            " tf_upsample (TFUpsample)       (1, 40, 40, 256)     0           ['tf_conv_33[0][0]']             \n",
            "                                                                                                  \n",
            " tf_concat (TFConcat)           (1, 40, 40, 512)     0           ['tf_upsample[0][0]',            \n",
            "                                                                  'tfc3_2[0][0]']                 \n",
            "                                                                                                  \n",
            " tfc3_4 (TFC3)                  (1, 40, 40, 256)     361216      ['tf_concat[0][0]']              \n",
            "                                                                                                  \n",
            " tf_conv_39 (TFConv)            (1, 40, 40, 128)     32896       ['tfc3_4[0][0]']                 \n",
            "                                                                                                  \n",
            " tf_upsample_1 (TFUpsample)     (1, 80, 80, 128)     0           ['tf_conv_39[0][0]']             \n",
            "                                                                                                  \n",
            " tf_concat_1 (TFConcat)         (1, 80, 80, 256)     0           ['tf_upsample_1[0][0]',          \n",
            "                                                                  'tfc3_1[0][0]']                 \n",
            "                                                                                                  \n",
            " tfc3_5 (TFC3)                  (1, 80, 80, 128)     90496       ['tf_concat_1[0][0]']            \n",
            "                                                                                                  \n",
            " tf_conv_45 (TFConv)            (1, 40, 40, 128)     147584      ['tfc3_5[0][0]']                 \n",
            "                                                                                                  \n",
            " tf_concat_2 (TFConcat)         (1, 40, 40, 256)     0           ['tf_conv_45[0][0]',             \n",
            "                                                                  'tf_conv_39[0][0]']             \n",
            "                                                                                                  \n",
            " tfc3_6 (TFC3)                  (1, 40, 40, 256)     295680      ['tf_concat_2[0][0]']            \n",
            "                                                                                                  \n",
            " tf_conv_51 (TFConv)            (1, 20, 20, 256)     590080      ['tfc3_6[0][0]']                 \n",
            "                                                                                                  \n",
            " tf_concat_3 (TFConcat)         (1, 20, 20, 512)     0           ['tf_conv_51[0][0]',             \n",
            "                                                                  'tf_conv_33[0][0]']             \n",
            "                                                                                                  \n",
            " tfc3_7 (TFC3)                  (1, 20, 20, 512)     1181184     ['tf_concat_3[0][0]']            \n",
            "                                                                                                  \n",
            " tf_detect (TFDetect)           ((1, 25200, 85),     229245      ['tfc3_5[0][0]',                 \n",
            "                                 [(1, 6400, 3, 85),               'tfc3_6[0][0]',                 \n",
            "                                 (1, 1600, 3, 85),                'tfc3_7[0][0]']                 \n",
            "                                 (1, 400, 3, 85)])                                                \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 7,225,885\n",
            "Trainable params: 0\n",
            "Non-trainable params: 7,225,885\n",
            "__________________________________________________________________________________________________\n",
            "2022-09-19 18:08:22.286134: W tensorflow/python/util/util.cc:368] Sets are not currently considered sequences, but this may change in the future, so consider avoiding using them.\n",
            "Assets written to: yolov5s_saved_model/assets\n",
            "\u001b[34m\u001b[1mTensorFlow SavedModel:\u001b[0m export success ✅ 10.1s, saved as yolov5s_saved_model (27.8 MB)\n",
            "\n",
            "\u001b[34m\u001b[1mTensorFlow Lite:\u001b[0m starting export with tensorflow 2.8.2...\n",
            "Found untraced functions such as tf_conv_2_layer_call_fn, tf_conv_2_layer_call_and_return_conditional_losses, tf_conv_3_layer_call_fn, tf_conv_3_layer_call_and_return_conditional_losses, tf_conv_4_layer_call_fn while saving (showing 5 of 208). These functions will not be directly callable after loading.\n",
            "Assets written to: /tmp/tmpt4lmyms8/assets\n",
            "2022-09-19 18:09:26.497583: W tensorflow/compiler/mlir/lite/python/tf_tfl_flatbuffer_helpers.cc:357] Ignored output_format.\n",
            "2022-09-19 18:09:26.497678: W tensorflow/compiler/mlir/lite/python/tf_tfl_flatbuffer_helpers.cc:360] Ignored drop_control_dependency.\n",
            "Estimated count of arithmetic ops: 18.144 G  ops, equivalently 9.072 G  MACs\n",
            "\u001b[34m\u001b[1mTensorFlow Lite:\u001b[0m export success ✅ 66.9s, saved as yolov5s-fp16.tflite (13.9 MB)\n",
            "\n",
            "Export complete (78.2s)\n",
            "Results saved to \u001b[1m/content/drive/MyDrive/yolov5\u001b[0m\n",
            "Detect:          python detect.py --weights yolov5s-fp16.tflite \n",
            "Validate:        python val.py --weights yolov5s-fp16.tflite \n",
            "PyTorch Hub:     model = torch.hub.load('ultralytics/yolov5', 'custom', 'yolov5s-fp16.tflite')\n",
            "Visualize:       https://netron.app\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Weights & Biases (optional)\n",
        "%pip install -q wandb  \n",
        "!wandb login  # use 'wandb disabled' or 'wandb enabled' to disable or enable\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YX_SIGLQtLDr",
        "outputId": "e9087b37-b894-431f-9f0e-2cb8b7d94943"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33myunhaaaa\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
          ]
        }
      ]
    }
  ]
}